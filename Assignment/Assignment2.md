

âœ… 1) FCFNN Drawing (Conceptual Diagram)
âœ… 2) Full TensorFlow.Keras Implementation
âœ… 3) Training + Testing Example
âœ… 4) Model Summary

à¦†à¦®à¦¿ à¦à¦–à¦¾à¦¨à§‡ MNIST dataset à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° à¦•à¦°à¦›à¦¿à¥¤

---

# ðŸ“˜ 1ï¸âƒ£ Drawing of Fully Connected Feed-Forward Neural Network (FCFNN)

### ðŸ”¹ My Preferred Architecture

* Input Layer â†’ 784 neurons (28Ã—28 image flattened)
* Hidden Layer 1 â†’ 512 neurons
* Hidden Layer 2 â†’ 256 neurons
* Hidden Layer 3 â†’ 128 neurons
* Output Layer â†’ 10 neurons (Softmax)

---

## ðŸ§  Network Diagram

```
                INPUT LAYER
        (784 neurons - flattened image)
                      â”‚
                      â–¼
            Hidden Layer 1 (512)
                 Activation: ReLU
                      â”‚
                      â–¼
            Hidden Layer 2 (256)
                 Activation: ReLU
                      â”‚
                      â–¼
            Hidden Layer 3 (128)
                 Activation: ReLU
                      â”‚
                      â–¼
             OUTPUT LAYER (10)
             Activation: Softmax
```

âœ” Fully Connected
âœ” Feed-Forward
âœ” No Convolution

---

# ðŸ“˜ 2ï¸âƒ£ Full Implementation Using TensorFlow.Keras

---

## ðŸ”µ Complete Working Code

```python
# ==========================================
# 1ï¸âƒ£ Import Libraries
# ==========================================
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Flatten, Input
from tensorflow.keras.datasets import mnist

# ==========================================
# 2ï¸âƒ£ Load Dataset (MNIST)
# ==========================================
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# ==========================================
# 3ï¸âƒ£ Preprocessing
# ==========================================

# Normalize pixel values
x_train = x_train / 255.0
x_test = x_test / 255.0

# ==========================================
# 4ï¸âƒ£ Build FCFNN Model (Functional API)
# ==========================================

inputs = Input(shape=(28, 28))

# Flatten 28Ã—28 â†’ 784
x = Flatten()(inputs)

# Hidden Layers
x = Dense(512, activation='relu', name='hidden1')(x)
x = Dense(256, activation='relu', name='hidden2')(x)
x = Dense(128, activation='relu', name='hidden3')(x)

# Output Layer
outputs = Dense(10, activation='softmax', name='output')(x)

model = Model(inputs, outputs)

# ==========================================
# 5ï¸âƒ£ Compile Model
# ==========================================

model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# ==========================================
# 6ï¸âƒ£ Show Model Summary
# ==========================================
model.summary()

# ==========================================
# 7ï¸âƒ£ Train Model
# ==========================================

history = model.fit(
    x_train,
    y_train,
    epochs=10,
    batch_size=64,
    validation_split=0.1
)

# ==========================================
# 8ï¸âƒ£ Evaluate Model
# ==========================================

loss, acc = model.evaluate(x_test, y_test)
print("Test Accuracy:", acc)

# ==========================================
# 9ï¸âƒ£ Plot Accuracy Curve
# ==========================================

plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title("Accuracy Curve")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.legend()
plt.show()
```

---

# ðŸ“˜ 3ï¸âƒ£ Model Architecture Explanation

```
Input (28Ã—28 image)
â†“
Flatten â†’ 784 neurons
â†“
Dense 512 (ReLU)
â†“
Dense 256 (ReLU)
â†“
Dense 128 (ReLU)
â†“
Dense 10 (Softmax)
```

---

# ðŸ“Š Parameter Flow Example

First Hidden Layer:

[
(784 Ã— 512) + 512 = 401,920
]

Total parameters â‰ˆ 550K+

---

# ðŸ§  Why This is FCFNN?

âœ” Every neuron connected to next layer
âœ” Only forward propagation
âœ” No convolution or pooling
âœ” Used for structured/tabular/simple image classification

---

# ðŸ“ Viva Ready Explanation

> A Fully Connected Feed-Forward Neural Network (FCFNN) was designed with three hidden layers (512, 256, and 128 neurons). The model was implemented using TensorFlow.Keras Functional API and trained on the MNIST dataset using sparse categorical crossentropy.

---

# ðŸŽ¯ Expected Performance

MNIST Accuracy â‰ˆ 97â€“98%

---



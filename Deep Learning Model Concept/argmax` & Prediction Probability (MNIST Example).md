

---

# üìò DOCUMENTATION: `argmax` & Prediction Probability (MNIST Example)

---

## üîπ 1. Model Prediction ‡¶Ü‡¶∏‡¶≤‡ßá ‡¶ï‡ßÄ?

‡¶Ø‡¶ñ‡¶® ‡¶§‡ßÅ‡¶Æ‡¶ø ‡¶≤‡¶ø‡¶ñ‡ßã:

```python
y_pred_prob = model.predict(x_test)
```

‡¶§‡¶ñ‡¶® model **final decision ‡¶¶‡ßá‡ßü ‡¶®‡¶æ**, ‡¶¨‡¶∞‡¶Ç ‡¶¶‡ßá‡ßü ‚Äî

üëâ **‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶æ class-‡¶è‡¶∞ probability**

### MNIST (10 digits) ‡¶π‡¶≤‡ßá:

‡¶è‡¶ï‡¶ü‡¶æ image ‡¶è‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø output ‡¶π‡ßü:

```python
[0.01, 0.00, 0.02, 0.01, 0.00, 0.03, 0.00, 0.90, 0.02, 0.01]
```

‡¶è‡¶ü‡¶æ‡¶∞ ‡¶Æ‡¶æ‡¶®‡ßá:

* Digit 0 ‚Üí 1%
* Digit 7 ‚Üí **90% (‡¶∏‡¶¨‡¶ö‡ßá‡ßü‡ßá ‡¶¨‡ßá‡¶∂‡¶ø)**
* ‡¶∏‡¶¨ probability ‡¶è‡¶∞ ‡¶Ø‡ßã‡¶ó‡¶´‡¶≤ = 1

---

## üîπ 2. `argmax` ‡¶ï‡ßÄ? (Core Concept)

### Definition

> **`argmax` array-‡¶è‡¶∞ ‡¶Æ‡¶ß‡ßç‡¶Ø‡ßá ‡¶Ø‡ßá‡¶á element ‡¶∏‡¶¨‡¶ö‡ßá‡ßü‡ßá ‡¶¨‡ßú, ‡¶§‡¶æ‡¶∞ index ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡ßá**

### Simple example

```python
a = [5, 20, 3]
np.argmax(a)   # output: 1
```

‡¶ï‡¶æ‡¶∞‡¶£:

* max value = 20
* index = 1

---

## üîπ 3. Classification ‡¶è `argmax` ‡¶ï‡ßá‡¶® ‡¶¶‡¶∞‡¶ï‡¶æ‡¶∞?

Model output:

```python
y_pred_prob.shape = (num_samples, num_classes)
```

‡¶Ü‡¶Æ‡¶æ‡¶¶‡ßá‡¶∞ ‡¶¶‡¶∞‡¶ï‡¶æ‡¶∞:

```python
[7, 0, 4, 1, ...]   # final predicted digit
```

‡¶§‡¶æ‡¶á ‡¶Ü‡¶Æ‡¶∞‡¶æ ‡¶≤‡¶ø‡¶ñ‡¶ø:

```python
y_pred = np.argmax(y_pred_prob, axis=1)
```

---

## üîπ 4. `axis=1` ‡¶Æ‡¶æ‡¶®‡ßá ‡¶ï‡ßÄ?

| axis     | ‡¶Ö‡¶∞‡ßç‡¶•                      |
| -------- | ------------------------- |
| `axis=0` | column-wise               |
| `axis=1` | **row-wise (‡¶è‡¶ï‡¶ü‡¶æ image)** |

üëâ ‡¶Ø‡ßá‡¶π‡ßá‡¶§‡ßÅ:

* 1 row = 1 image
* ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶æ image ‡¶•‡ßá‡¶ï‡ßá max probability ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡¶§‡ßá ‡¶ö‡¶æ‡¶á

‚úî ‡¶§‡¶æ‡¶á `axis=1`

---

## üîπ 5. Full Flow (Prediction Logic)

```text
Image
 ‚Üì
Softmax layer
 ‚Üì
Probability vector (10 values)
 ‚Üì
argmax
 ‚Üì
Final digit prediction
```

---

## üîπ 6. Image + Probability ‡¶è‡¶ï‡¶∏‡¶æ‡¶•‡ßá ‡¶ï‡¶ø‡¶≠‡¶æ‡¶¨‡ßá Print ‡¶ï‡¶∞‡¶¨‡ßá

### üéØ Goal:

‡¶è‡¶ï‡¶ü‡¶æ digit image ‡¶¶‡ßá‡¶ñ‡¶æ‡¶¨‡ßá
‡¶∏‡¶æ‡¶•‡ßá ‡¶¶‡ßá‡¶ñ‡¶æ‡¶¨‡ßá:

* True label
* Predicted label
* ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶æ digit-‡¶è‡¶∞ probability

---

## üîπ Step 1: Prediction ‡¶®‡¶æ‡¶ì

```python
y_pred_prob = model.predict(x_test, verbose=0)
y_pred = np.argmax(y_pred_prob, axis=1)

y_true = np.argmax(y_test, axis=1)
```

---

## üîπ Step 2: ‡¶è‡¶ï‡¶ü‡¶ø image ‡¶¨‡ßá‡¶õ‡ßá ‡¶®‡¶æ‡¶ì

```python
idx = 0   # ‡¶Ø‡ßá‡¶ï‡ßã‡¶®‡ßã index
```

---

## üîπ Step 3: Image + Probability Print

```python
plt.figure(figsize=(12,4))

# üîπ Image
plt.subplot(1,2,1)
plt.imshow(x_test[idx], cmap='gray')
plt.title(f"True: {y_true[idx]} | Pred: {y_pred[idx]}")
plt.axis('off')

# üîπ Probability bar chart
plt.subplot(1,2,2)
plt.bar(range(10), y_pred_prob[idx])
plt.xlabel("Digit")
plt.ylabel("Probability")
plt.title("Prediction Probabilities")
plt.show()
```

üëâ ‡¶è‡¶§‡ßá ‡¶§‡ßÅ‡¶Æ‡¶ø **‡¶ö‡ßã‡¶ñ‡ßá ‡¶¶‡ßá‡¶ñ‡¶¨‡ßá model ‡¶ï‡¶§‡¶ü‡¶æ confident**‡•§

---

## üñºÔ∏è Visual Idea (MNIST digits)

![Image](https://www.researchgate.net/publication/382145539/figure/fig4/AS%3A11431281259781353%401720667202742/Please-zoom-in-for-detail-Average-Softmax-Probabilities-for-Correctly-and-Incorrectly.ppm)

![Image](https://miro.medium.com/v2/resize%3Afit%3A1296/1%2AXW3q3RmROtKbJSK13yHccg.jpeg)

(‡¶§‡ßã‡¶Æ‡¶æ‡¶∞ output ‡¶è ‡¶è‡¶∞‡¶ï‡¶Æ image + bar chart ‡¶Ü‡¶∏‡¶¨‡ßá)

---

## üîπ 7. Multiple Image + Probability (Bonus)

```python
plt.figure(figsize=(15,6))

for i in range(5):
    plt.subplot(2,5,i+1)
    plt.imshow(x_test[i], cmap='gray')
    plt.title(f"T:{y_true[i]} P:{y_pred[i]}")
    plt.axis('off')

    plt.subplot(2,5,i+6)
    plt.bar(range(10), y_pred_prob[i])
    plt.xticks(range(10))
```

---

## üîπ 8. Common Mistakes üö®

‚ùå `argmax` ‡¶®‡¶æ ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßá accuracy ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡¶æ
‚ùå `axis=0` ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶æ
‚ùå probability vector ‡¶ï‡ßá final label ‡¶ß‡¶∞‡¶æ

---

## üîë One-Line Summary

> **Softmax probability ‡¶¨‡¶≤‡ßá ‚Äú‡¶ï‡¶§‡¶ü‡¶æ ‡¶¨‡¶ø‡¶∂‡ßç‡¶¨‡¶æ‡¶∏‚Äù, `argmax` ‡¶¨‡¶≤‡ßá ‚Äúfinal decision‚Äù**

---



---

## üîπ ‡¶≤‡¶æ‡¶á‡¶®‡¶ü‡¶æ ‡¶Ü‡¶¨‡¶æ‡¶∞ ‡¶¶‡ßá‡¶ñ‡¶ø

```python
y_true = np.argmax(y_test, axis=1)
```

---

## 1Ô∏è‚É£ `y_test` ‡¶Ü‡¶∏‡¶≤‡ßá ‡¶ï‡ßÄ?

‡¶§‡ßã‡¶Æ‡¶æ‡¶∞ ‡¶ï‡ßã‡¶°‡ßá ‡¶§‡ßÅ‡¶Æ‡¶ø ‡¶≤‡¶ø‡¶ñ‡ßá‡¶õ‡ßã:

```python
y_test = to_categorical(y_test, num_classes)
```

‡¶Æ‡¶æ‡¶®‡ßá ‡¶è‡¶ñ‡¶® `y_test` ‡¶Ü‡¶∞ integer label ‡¶®‡¶æ, ‡¶¨‡¶∞‡¶Ç **one-hot encoded label**‡•§

### Example (MNIST, digit = 3)

```python
y_test[0] = [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]
```

---

## 2Ô∏è‚É£ One-hot encoding ‡¶ï‡ßá‡¶® ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶æ ‡¶π‡ßü?

‡¶ï‡¶æ‡¶∞‡¶£:

* `softmax + categorical_crossentropy`
* loss function ‡¶ö‡¶æ‡ßü **vector format label**

‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ analysis ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶∏‡¶Æ‡ßü:

* accuracy
* confusion matrix
* per-digit accuracy

üëâ integer label ‡¶¶‡¶∞‡¶ï‡¶æ‡¶∞

---

## 3Ô∏è‚É£ `np.argmax()` ‡¶è‡¶ñ‡¶æ‡¶®‡ßá ‡¶ï‡ßÄ ‡¶ï‡¶∞‡¶õ‡ßá?

### Definition:

> **array-‡¶è‡¶∞ ‡¶∏‡¶¨‡¶ö‡ßá‡ßü‡ßá ‡¶¨‡ßú value-‡¶è‡¶∞ index ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡ßá**

One-hot vector ‡¶è:

* ‡¶∂‡ßÅ‡¶ß‡ßÅ ‡¶è‡¶ï‡¶ü‡¶æ‡¶á `1`
* ‡¶¨‡¶æ‡¶ï‡¶ø‡¶ó‡ßÅ‡¶≤‡ßã `0`

‡¶§‡¶æ‡¶á:

```python
np.argmax([0, 0, 0, 1, 0, 0, 0, 0, 0, 0])
```

Output:

```python
3
```

---

## 4Ô∏è‚É£ ‡¶§‡¶æ‡¶π‡¶≤‡ßá `axis=1` ‡¶ï‡ßá‡¶®?

`y_test` ‡¶è‡¶∞ shape:

```python
(num_samples, num_classes)
```

Example:

```python
(10000, 10)
```

‡¶è‡¶ñ‡¶æ‡¶®‡ßá:

* 1 row = 1 sample
* 10 column = 10 digit

‡¶Ü‡¶Æ‡¶∞‡¶æ ‡¶ö‡¶æ‡¶á:
üëâ ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶æ row ‡¶•‡ßá‡¶ï‡ßá class ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡¶§‡ßá

‡¶§‡¶æ‡¶á:

```python
axis=1
```

---

## 5Ô∏è‚É£ ‡¶™‡ßÅ‡¶∞‡ßã flow ‡¶è‡¶ï‡¶∏‡¶æ‡¶•‡ßá ‡¶¶‡ßá‡¶ñ‡ßã

### Before training:

```python
y_test = [7, 2, 1, 0]
```

### After `to_categorical`:

```python
[
 [0,0,0,0,0,0,0,1,0,0],
 [0,0,1,0,0,0,0,0,0,0],
 [0,1,0,0,0,0,0,0,0,0],
 [1,0,0,0,0,0,0,0,0,0]
]
```

### After `argmax`:

```python
y_true = [7, 2, 1, 0]
```

üëâ ‡¶Ü‡¶Æ‡¶∞‡¶æ **‡¶Ü‡¶¨‡¶æ‡¶∞ original label** ‡¶´‡¶ø‡¶∞‡ßá ‡¶™‡ßá‡¶≤‡¶æ‡¶Æ‡•§

---

## 6Ô∏è‚É£ ‡¶ï‡ßá‡¶® `y_pred` ‡¶Ü‡¶∞ `y_true` ‡¶¶‡ßÅ‡¶á‡¶ü‡¶æ‡¶á integer ‡¶ï‡¶∞‡¶æ ‡¶π‡ßü?

‡¶ï‡¶æ‡¶∞‡¶£:

* Compare ‡¶ï‡¶∞‡¶§‡ßá ‡¶∏‡¶π‡¶ú
* Accuracy ‡¶π‡¶ø‡¶∏‡¶æ‡¶¨ ‡¶∏‡¶π‡¶ú
* Confusion matrix ‡¶¨‡¶æ‡¶®‡¶æ‡¶®‡ßã ‡¶∏‡¶π‡¶ú

```python
y_pred == y_true
```

---

## üîë ‡¶è‡¶ï ‡¶≤‡¶æ‡¶á‡¶®‡ßá ‡¶Æ‡¶®‡ßá ‡¶∞‡¶æ‡¶ñ‡ßã

> **`np.argmax(y_test, axis=1)` = one-hot label ‚Üí ‡¶Ü‡¶∏‡¶≤ digit**

---

## ‚ö†Ô∏è Important Note

‡¶Ø‡¶¶‡¶ø ‡¶§‡ßÅ‡¶Æ‡¶ø `sparse_categorical_crossentropy` ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶§‡ßá:

```python
loss='sparse_categorical_crossentropy'
```

‡¶§‡¶æ‡¶π‡¶≤‡ßá:

* `to_categorical` ‡¶≤‡¶æ‡¶ó‡¶§ ‡¶®‡¶æ
* `y_test` ‡¶Ü‡¶ó‡ßá‡¶á integer ‡¶•‡¶æ‡¶ï‡¶§
* `argmax(y_test)` ‡¶≤‡¶æ‡¶ó‡¶§ ‡¶®‡¶æ

---





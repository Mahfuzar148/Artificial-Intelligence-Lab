

---

# ЁЯУШ LOSS FUNCTION тАФ FULL DOCUMENTATION (Deep Learning)

---

## 1я╕ПтГг Loss Function ржХрзА?

**Loss function** ржорж╛ржкрзЗ:

> Model ржпрж╛ predict ржХрж░рзЗржЫрзЗ (┼╖)
> ржЖрж░ ржЖрж╕рж▓ answer (y)
> ржПржЗ ржжрзБржЗржЯрж╛рж░ ржоржзрзНржпрзЗ ржкрж╛рж░рзНржержХрзНржп ржХржд

ЁЯУМ Training ржПрж░ рж▓ржХрзНрж╖рзНржп:

```text
Loss minimize ржХрж░рж╛
```

Optimizer (SGD, Adam ржЗрждрзНржпрж╛ржжрж┐) ржПржЗ loss ржХржорж╛ржирзЛрж░ ржЬржирзНржп weight update ржХрж░рзЗред

---

## 2я╕ПтГг Training Flow (Big Picture)

```
Input тЖТ Model тЖТ Prediction
              тЖУ
        Loss Function
              тЖУ
        Optimizer
              тЖУ
        Weight Update
```

---

## 3я╕ПтГг Loss Function ржПрж░ ржзрж░ржи

### ЁЯФ╣ A. Regression Loss

Continuous value predict ржХрж░рж▓рзЗ

| Loss  | ржХрж╛ржЬ                 |
| ----- | ------------------- |
| MSE   | Mean Squared Error  |
| MAE   | Mean Absolute Error |
| Huber | MSE + MAE mix       |

---

### ЁЯФ╣ B. Classification Loss

Class predict ржХрж░рж▓рзЗ

| Problem                    | Output  | Loss                            |
| -------------------------- | ------- | ------------------------------- |
| Binary                     | sigmoid | binary_crossentropy             |
| Multiclass                 | softmax | categorical_crossentropy        |
| Multiclass (integer label) | softmax | sparse_categorical_crossentropy |

---

## 4я╕ПтГг Categorical Crossentropy (DETAILS)

### ЁЯУМ ржмрзНржпржмрж╣рж╛рж░ рж╣ржмрзЗ ржпржЦржи:

* Class > 2
* Output layer = `softmax`
* Label = **one-hot encoded**

---

### ЁЯФ╣ Mathematical Formula

```text
L = тИТ ╬г yс╡в log(┼╖с╡в)
```

* yс╡в = true label (0 or 1)
* ┼╖с╡в = predicted probability

ЁЯСЙ рж╢рзБржзрзБ ржпрзЗржЗ class ржЯрж╛ true (1), рж╕рзЗржЯрж╛рж░ log probability ржирзЗржУрзЯрж╛ рж╣рзЯред

---

### ЁЯФ╣ Example

True label:

```python
y_true = [0, 1, 0]
```

Prediction:

```python
y_pred = [0.1, 0.7, 0.2]
```

Loss:

```text
= тИТlog(0.7)
= 0.357
```

тЬФ High probability тЖТ low loss
тЭМ Low probability тЖТ high loss

---

### ЁЯФ╣ Keras ржмрзНржпржмрж╣рж╛рж░

```python
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)
```

---

## 5я╕ПтГг Sparse Categorical Crossentropy

### ЁЯУМ ржкрж╛рж░рзНржержХрзНржп рж╢рзБржзрзБ label format ржП

| Type        | Example   |
| ----------- | --------- |
| categorical | [0, 1, 0] |
| sparse      | 1         |

### ЁЯФ╣ ржмрзНржпржмрж╣рж╛рж░

```python
model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy'
)
```

тЬФ ржПржЦрж╛ржирзЗ `to_categorical` рж▓рж╛ржЧржмрзЗ ржирж╛

---

## 6я╕ПтГг Binary Crossentropy

### ЁЯУМ ржмрзНржпржмрж╣рж╛рж░ рж╣ржмрзЗ ржпржЦржи:

* 2ржЯрж╛ class
* Output = 1 neuron
* Activation = sigmoid

### ЁЯФ╣ Formula

```text
L = тИТ[ y log(p) + (1тИТy) log(1тИТp) ]
```

### ЁЯФ╣ Keras

```python
Dense(1, activation='sigmoid')
loss='binary_crossentropy'
```

---

## 7я╕ПтГг Regression Loss (рж╕ржВржХрзНрж╖рзЗржкрзЗ)

### ЁЯФ╣ Mean Squared Error (MSE)

```text
L = (y тИТ ┼╖)┬▓
```

тЬФ Large error ржХрзЗ ржмрзЗрж╢рж┐ рж╢рж╛рж╕рзНрждрж┐ ржжрзЗрзЯ
тЭМ Outlier sensitive

---

### ЁЯФ╣ Mean Absolute Error (MAE)

```text
L = |y тИТ ┼╖|
```

тЬФ Robust to outliers
тЭМ Gradient constant тЖТ slow learning

---

### ЁЯФ╣ Huber Loss

```text
Small error тЖТ MSE
Large error тЖТ MAE
```

тЬФ Best of both worlds

---

## 8я╕ПтГг Loss vs Metric (Confusion ржжрзВрж░ ржХрж░рзЛ)

| Loss               | Metric                      |
| ------------------ | --------------------------- |
| Training ржПрж░ ржЬржирзНржп   | Reporting ржПрж░ ржЬржирзНржп           |
| Backpropagation рж╣рзЯ | Backprop рж╣рзЯ ржирж╛              |
| Differentiable     | Non-differentiable рж╣рждрзЗ ржкрж╛рж░рзЗ |

Example:

```python
loss='categorical_crossentropy'
metrics=['accuracy']
```

---

## 9я╕ПтГг Common Mistakes ЁЯЪи

### тЭМ ржнрзБрж▓ 1

```python
softmax + binary_crossentropy
```

### тЭМ ржнрзБрж▓ 2

```python
categorical_crossentropy + integer labels
```

### тЭМ ржнрзБрж▓ 3

```python
sigmoid + categorical_crossentropy
```

---

## ЁЯФЯ Correct Combination Cheat Sheet ЁЯза

| Output Layer      | Classes | Loss                            |
| ----------------- | ------- | ------------------------------- |
| Dense(1, sigmoid) | 2       | binary_crossentropy             |
| Dense(C, softmax) | C>2     | categorical_crossentropy        |
| Dense(C, softmax) | C>2     | sparse_categorical_crossentropy |

---

## 1я╕ПтГг1я╕ПтГг Advanced Notes (Important)

### ЁЯФ╣ Numerical Stability

Keras internally:

```text
softmax + crossentropy тЖТ fused implementation
```

ЁЯСЙ Overflow / underflow ржПрзЬрж╛рзЯ

---

### ЁЯФ╣ Class Imbalance рж╣рж▓рзЗ

```python
class_weight = {0:1, 1:5}
model.fit(..., class_weight=class_weight)
```

---

## ЁЯФС One-line Summary

> **Loss function рж╣рж▓рзЛ model ржПрж░ teacher тАФ рж╕рзЗ ржмрж▓рзЗ ржжрзЗрзЯ тАЬрждрзБржорж┐ ржХрждржЯрж╛ ржнрзБрж▓ ржХрж░ржЫрзЛтАЭ**

---




---

# ðŸ“˜ Metrics â€“ Full Documentation (Accuracy, Precision, Recall)

---

## ðŸ”¹ 1. Metrics à¦•à§€?

**Metrics** à¦¹à¦²à§‹ à¦à¦®à¦¨ measurement à¦¯à§‡à¦—à§à¦²à§‹ à¦¦à¦¿à§Ÿà§‡ à¦†à¦®à¦°à¦¾â€”

ðŸ‘‰ Model à¦•à¦¤à¦Ÿà¦¾ à¦­à¦¾à¦²à§‹ prediction à¦•à¦°à¦›à§‡
ðŸ‘‰ Training / testing à¦¸à¦®à§Ÿ performance à¦•à§‡à¦®à¦¨

à¦¤à¦¾ à¦¬à§à¦à¦¿à¥¤

ðŸ“Œ à¦—à§à¦°à§à¦¤à§à¦¬à¦ªà§‚à¦°à§à¦£ à¦•à¦¥à¦¾:

* **Loss** â†’ model à¦¶à§‡à¦–à¦¾à¦° à¦œà¦¨à§à¦¯ (backpropagation)
* **Metrics** â†’ model à¦¬à¦¿à¦šà¦¾à¦° à¦•à¦°à¦¾à¦° à¦œà¦¨à§à¦¯ (human-readable)

---

## ðŸ”¹ 2. `metrics` à¦•à§‹à¦¥à¦¾à§Ÿ à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° à¦¹à§Ÿ?

```python
model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy', 'precision', 'recall']
)
```

ðŸ“Œ Metrics:

* Training output-à¦ à¦¦à§‡à¦–à¦¾à§Ÿ
* `model.evaluate()`-à¦ return à¦¹à§Ÿ
* Training process **change à¦•à¦°à§‡ à¦¨à¦¾**

---

## ðŸ”¹ 3. Confusion Matrix (Base Concept)

à¦¸à¦¬ classification metric à¦¬à§‹à¦à¦¾à¦° à¦œà¦¨à§à¦¯ à¦à¦Ÿà¦¾ à¦œà¦¾à¦¨à¦¾ à¦¬à¦¾à¦§à§à¦¯à¦¤à¦¾à¦®à§‚à¦²à¦• ðŸ‘‡

|                | Predicted YES       | Predicted NO        |
| -------------- | ------------------- | ------------------- |
| **Actual YES** | TP (True Positive)  | FN (False Negative) |
| **Actual NO**  | FP (False Positive) | TN (True Negative)  |

---

# ðŸ”¹ 4. Accuracy

## ðŸ‘‰ Accuracy à¦•à§€?

**Accuracy** à¦¬à¦²à§‡ à¦¦à§‡à§Ÿ:

> à¦®à§‹à¦Ÿ prediction-à¦à¦° à¦®à¦§à§à¦¯à§‡ à¦•à§Ÿà¦Ÿà¦¾ à¦ à¦¿à¦• à¦¹à§Ÿà§‡à¦›à§‡

---

### ðŸ“ Formula

[
\text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}
]

---

### âœ… Keras

```python
metrics=['accuracy']
```

---

### ðŸ” Example

* Total = 100
* Correct = 90

ðŸ‘‰ Accuracy = **90%**

---

### âŒ Problem with Accuracy

Class imbalance à¦¥à¦¾à¦•à¦²à§‡ misleading à¦¹à§Ÿ

Example:

* 95 negative
* 5 positive
* Model à¦¸à¦¬ negative à¦¬à¦²à¦²

ðŸ‘‰ Accuracy = 95% âŒ (à¦•à¦¿à¦¨à§à¦¤à§ useless)

---

# ðŸ”¹ 5. Precision â­ (False Alarm Control)

## ðŸ‘‰ Precision à¦•à§€?

**Precision** à¦¬à¦²à§‡ à¦¦à§‡à§Ÿ:

> Model à¦¯à§‡à¦—à§à¦²à§‹à¦•à§‡ YES à¦¬à¦²à§‡à¦›à§‡, à¦¤à¦¾à¦° à¦®à¦§à§à¦¯à§‡ à¦•à§Ÿà¦Ÿà¦¾ à¦¸à¦¤à§à¦¯à¦¿ YES

---

### ðŸ“ Formula

[
\text{Precision} = \frac{TP}{TP + FP}
]

---

### âœ… Keras

```python
metrics=['precision']
```

---

### ðŸ” Example (Spam Detection)

| Case | Value |
| ---- | ----- |
| TP   | 40    |
| FP   | 10    |

ðŸ‘‰ Precision = 40 / (40+10) = **0.80**

ðŸ“Œ à¦®à¦¾à¦¨à§‡:

> à§®à§¦% à¦¸à¦®à§Ÿ model à¦ à¦¿à¦•à¦­à¦¾à¦¬à§‡ spam à¦§à¦°à§‡à¦›à§‡

---

### ðŸ§  Precision à¦•à¦–à¦¨ à¦¦à¦°à¦•à¦¾à¦°?

| Use Case        | Reason                       |
| --------------- | ---------------------------- |
| Spam detection  | False alarm à¦•à¦®à¦¾à¦¤à§‡            |
| Email filter    | Good mail block à¦¨à¦¾ à¦•à¦°à¦¤à§‡      |
| Fraud detection | Innocent user accuse à¦¨à¦¾ à¦•à¦°à¦¤à§‡ |

ðŸ“Œ **False Positive costly à¦¹à¦²à§‡ â†’ Precision à¦—à§à¦°à§à¦¤à§à¦¬à¦ªà§‚à¦°à§à¦£**

---

# ðŸ”¹ 6. Recall â­ (Missing Case Control)

## ðŸ‘‰ Recall à¦•à§€?

**Recall** à¦¬à¦²à§‡ à¦¦à§‡à§Ÿ:

> à¦†à¦¸à¦² YES à¦—à§à¦²à§‹à¦° à¦®à¦§à§à¦¯à§‡ à¦•à§Ÿà¦Ÿà¦¾ model à¦§à¦°à¦¤à§‡ à¦ªà§‡à¦°à§‡à¦›à§‡

---

### ðŸ“ Formula

[
\text{Recall} = \frac{TP}{TP + FN}
]

---

### âœ… Keras

```python
metrics=['recall']
```

---

### ðŸ” Example (Disease Detection)

| Case | Value |
| ---- | ----- |
| TP   | 45    |
| FN   | 5     |

ðŸ‘‰ Recall = 45 / (45+5) = **0.90**

ðŸ“Œ à¦®à¦¾à¦¨à§‡:

> à§¯à§¦% à¦°à§‹à¦—à§€ detect à¦¹à§Ÿà§‡à¦›à§‡

---

### ðŸ§  Recall à¦•à¦–à¦¨ à¦¦à¦°à¦•à¦¾à¦°?

| Use Case          | Reason                   |
| ----------------- | ------------------------ |
| Disease detection | Patient miss à¦•à¦°à¦¾ à¦¯à¦¾à¦¬à§‡ à¦¨à¦¾ |
| Cancer screening  | False negative deadly    |
| Security threat   | Threat miss à¦•à¦°à¦¾ à¦¯à¦¾à¦¬à§‡ à¦¨à¦¾  |

ðŸ“Œ **False Negative costly à¦¹à¦²à§‡ â†’ Recall à¦—à§à¦°à§à¦¤à§à¦¬à¦ªà§‚à¦°à§à¦£**

---

# ðŸ”¹ 7. Precision vs Recall (Most Important)

| Aspect         | Precision            | Recall                |
| -------------- | -------------------- | --------------------- |
| Focus          | False Positive       | False Negative        |
| Question       | â€œYES à¦¬à¦²à¦²à§‡ à¦•à¦¤à¦Ÿà¦¾ à¦ à¦¿à¦•?â€ | â€œà¦¸à¦¬ YES à¦§à¦°à¦¤à§‡ à¦ªà§‡à¦°à§‡à¦›à¦¿?â€ |
| Important when | Innocent punish      | Real case miss        |

---

## ðŸ§  Easy Memory Trick â­

* **Precision** â†’ *How precise my YES is*
* **Recall** â†’ *How much I recalled from real YES*

---

# ðŸ”¹ 8. Accuracy vs Precision vs Recall

| Metric    | Measures            | Problem              |
| --------- | ------------------- | -------------------- |
| Accuracy  | Overall correctness | Fails on imbalance   |
| Precision | False alarm         | Miss real cases      |
| Recall    | Missing cases       | Too many false alarm |

---

# ðŸ”¹ 9. Keras-à¦ à¦•à§€à¦­à¦¾à¦¬à§‡ à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° à¦¹à§Ÿ?

### âœ… Binary classification

```python
model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy', 'precision', 'recall']
)
```

---

### âœ… Evaluate return

```python
loss, acc, prec, rec = model.evaluate(x_test, y_test)
```

---

# ðŸ”¹ 10. Common Mistakes âŒ

### âŒ Accuracy-à¦‡ à¦¸à¦¬

```python
metrics=['accuracy']  # imbalance data
```

---

### âŒ Regression-à¦ precision/recall

```python
metrics=['precision']  # WRONG
```

---

## ðŸ”¹ 11. Exam / Viva One-Liners â­

* **Accuracy overall correctness à¦®à¦¾à¦ªà§‡**
* **Precision false positive control à¦•à¦°à§‡**
* **Recall false negative control à¦•à¦°à§‡**
* **Medical domain â†’ Recall important**
* **Spam/Fraud â†’ Precision important**

---

# ðŸ”¹ 12. Final Summary (Golden)

> ðŸ”¹ Loss model à¦¶à§‡à¦–à¦¾à§Ÿ
> ðŸ”¹ Accuracy à¦®à¦¾à¦¨à§à¦·à¦•à§‡ à¦¬à§à¦à¦¾à§Ÿ
> ðŸ”¹ Precision à¦¬à¦²à§‡ YES à¦•à¦¤à¦Ÿà¦¾ trustworthy
> ðŸ”¹ Recall à¦¬à¦²à§‡ à¦•à¦¤à¦Ÿà¦¾ YES à¦§à¦°à¦¾ à¦ªà§œà§‡à¦›à§‡

---


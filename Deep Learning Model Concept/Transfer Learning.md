

* ‚úÖ Pre-trained VGG16 (ImageNet)
* ‚úÖ include_top=False
* ‚úÖ Base model freeze
* ‚úÖ Custom classifier add
* ‚úÖ Compile
* ‚úÖ Train
* ‚úÖ Evaluate

---

# üìò Transfer Learning Full Code Example (VGG16)

---

## üü¢ Step 1: Import Libraries

```python
import tensorflow as tf
import numpy as np
from tensorflow.keras.applications import VGG16
from tensorflow.keras.layers import Dense, Flatten, Input
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
```

---

## üü¢ Step 2: Load Example Data (Dummy Example)

‡¶è‡¶ñ‡¶æ‡¶®‡ßá demonstration ‡¶è‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø random data ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶õ‡¶ø‡•§

```python
# Dummy dataset (100 images)
x_train = np.random.rand(100, 224, 224, 3)
y_train = tf.keras.utils.to_categorical(np.random.randint(0, 5, 100), 5)

x_test = np.random.rand(20, 224, 224, 3)
y_test = tf.keras.utils.to_categorical(np.random.randint(0, 5, 20), 5)
```

---

## üü¢ Step 3: Load Pre-trained VGG16

```python
base_model = VGG16(
    weights='imagenet',
    include_top=False,
    input_shape=(224, 224, 3)
)
```

---

### üîé Explanation:

* weights='imagenet' ‚Üí Pre-trained weights load
* include_top=False ‚Üí Fully connected layer ‡¶¨‡¶æ‡¶¶
* ‡¶è‡¶ñ‡¶® ‡¶∂‡ßÅ‡¶ß‡ßÅ‡¶Æ‡¶æ‡¶§‡ßç‡¶∞ convolutional feature extractor ‡¶•‡¶æ‡¶ï‡¶¨‡ßá

---

## üü¢ Step 4: Freeze Base Model

```python
base_model.trainable = False
```

### ‡¶ï‡ßá‡¶®?

Pre-trained weights ‡¶Ø‡ßá‡¶® ‡¶™‡¶∞‡¶ø‡¶¨‡¶∞‡ßç‡¶§‡¶® ‡¶®‡¶æ ‡¶π‡ßü‡•§

---

## üü¢ Step 5: Add Custom Classifier

```python
inputs = base_model.input
x = base_model.output

x = Flatten()(x)
x = Dense(256, activation='relu')(x)
outputs = Dense(5, activation='softmax')(x)

model = Model(inputs, outputs)
```

---

### üîé Structure ‡¶è‡¶ñ‡¶® ‡¶è‡¶Æ‡¶®:

```
Input ‚Üí VGG16 Conv Blocks ‚Üí Flatten ‚Üí Dense ‚Üí Output
```

---

## üü¢ Step 6: Compile Model

```python
model.compile(
    optimizer=Adam(learning_rate=0.001),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)
```

---

## üü¢ Step 7: Train Model

```python
history = model.fit(
    x_train,
    y_train,
    epochs=5,
    batch_size=16,
    validation_split=0.2
)
```

---

## üü¢ Step 8: Evaluate Model

```python
loss, acc = model.evaluate(x_test, y_test)
print("Test Accuracy:", acc)
```

---

# üî• Complete Final Code (All Together)

```python
import tensorflow as tf
import numpy as np
from tensorflow.keras.applications import VGG16
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam

# Dummy Data
x_train = np.random.rand(100, 224, 224, 3)
y_train = tf.keras.utils.to_categorical(np.random.randint(0, 5, 100), 5)

x_test = np.random.rand(20, 224, 224, 3)
y_test = tf.keras.utils.to_categorical(np.random.randint(0, 5, 20), 5)

# Load Pre-trained Model
base_model = VGG16(
    weights='imagenet',
    include_top=False,
    input_shape=(224, 224, 3)
)

# Freeze Base
base_model.trainable = False

# Add Custom Layers
x = base_model.output
x = Flatten()(x)
x = Dense(256, activation='relu')(x)
outputs = Dense(5, activation='softmax')(x)

model = Model(base_model.input, outputs)

# Compile
model.compile(
    optimizer=Adam(learning_rate=0.001),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Train
model.fit(
    x_train,
    y_train,
    epochs=5,
    batch_size=16,
    validation_split=0.2
)

# Evaluate
loss, acc = model.evaluate(x_test, y_test)
print("Test Accuracy:", acc)
```

---

# üß† Transfer Learning Concept Summary

### üîπ Phase 1 ‚Üí Feature Extraction

* Base model freeze
* Only new Dense layers train

### üîπ Phase 2 ‚Üí Fine-tuning (Optional)

* ‡¶ï‡¶ø‡¶õ‡ßÅ convolution layer unfreeze ‡¶ï‡¶∞‡¶æ
* Small learning rate ‡¶¶‡¶ø‡ßü‡ßá train

---

# üîµ Fine-Tuning Example (Advanced)

```python
base_model.trainable = True

for layer in base_model.layers[:-4]:
    layer.trainable = False

model.compile(
    optimizer=Adam(learning_rate=1e-5),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)
```

---

# üéØ When To Use Transfer Learning?

* Dataset ‡¶õ‡ßã‡¶ü ‡¶π‡¶≤‡ßá
* Faster training ‡¶ö‡¶æ‡¶á‡¶≤‡ßá
* High accuracy ‡¶¶‡¶∞‡¶ï‡¶æ‡¶∞ ‡¶π‡¶≤‡ßá

---

# üìù Viva Ready Answer

> Transfer learning ‡¶π‡¶≤‡ßã ‡¶è‡¶Æ‡¶® ‡¶è‡¶ï‡¶ü‡¶ø technique ‡¶Ø‡ßá‡¶ñ‡¶æ‡¶®‡ßá pre-trained model-‡¶è‡¶∞ convolutional ‡¶Ö‡¶Ç‡¶∂ ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßá ‡¶®‡¶§‡ßÅ‡¶® dataset-‡¶è‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø custom classifier ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡¶æ ‡¶π‡ßü‡•§ ‡¶è‡¶§‡ßá training time ‡¶ï‡¶Æ ‡¶≤‡¶æ‡¶ó‡ßá ‡¶è‡¶¨‡¶Ç accuracy ‡¶≠‡¶æ‡¶≤‡ßã ‡¶π‡ßü‡•§

---


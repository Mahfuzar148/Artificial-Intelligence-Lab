

---

# üìò DATASET LOADING ‚Äî FULL DOCUMENTATION (TensorFlow / Keras)

---

## 1Ô∏è‚É£ Keras Built-in Dataset (‡¶∏‡¶¨‡¶ö‡ßá‡ßü‡ßá ‡¶∏‡¶π‡¶ú)

TensorFlow ‡¶ï‡¶ø‡¶õ‡ßÅ dataset ‡¶Ü‡¶ó‡ßá ‡¶•‡ßá‡¶ï‡ßá‡¶á ‡¶¶‡¶ø‡ßü‡ßá ‡¶∞‡¶æ‡¶ñ‡ßá‡•§

### üìÇ Available datasets

| Dataset        | Problem                 |
| -------------- | ----------------------- |
| MNIST          | Handwritten digits      |
| Fashion-MNIST  | Clothing classification |
| CIFAR-10       | 10 object classes       |
| CIFAR-100      | 100 object classes      |
| IMDB           | Text sentiment          |
| Reuters        | News classification     |
| Boston Housing | Regression              |

---

### üîπ Import rule (‡¶∏‡¶¨‡¶ó‡ßÅ‡¶≤‡ßã‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø same)

```python
import tensorflow as tf
```

---

### üîπ General syntax

```python
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.DATASET_NAME.load_data()
```

---

### üîπ Examples

#### MNIST

```python
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()
```

#### Fashion-MNIST

```python
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()
```

#### CIFAR-10 (RGB image)

```python
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()
```

---

### üîπ Shape difference

| Dataset       | x_train shape      |
| ------------- | ------------------ |
| MNIST         | (60000, 28, 28)    |
| Fashion-MNIST | (60000, 28, 28)    |
| CIFAR-10      | (50000, 32, 32, 3) |

---

## 2Ô∏è‚É£ CSV / Tabular Dataset Load

### üîπ Using Pandas

```python
import pandas as pd

df = pd.read_csv("data.csv")
X = df.drop("label", axis=1)
y = df["label"]
```

---

### üîπ Convert to NumPy

```python
X = X.values
y = y.values
```

---

## 3Ô∏è‚É£ Image Dataset (Folder Structure)

### üìÅ Folder format (mandatory)

```
dataset/
 ‚îú‚îÄ‚îÄ train/
 ‚îÇ   ‚îú‚îÄ‚îÄ cat/
 ‚îÇ   ‚îî‚îÄ‚îÄ dog/
 ‚îî‚îÄ‚îÄ test/
     ‚îú‚îÄ‚îÄ cat/
     ‚îî‚îÄ‚îÄ dog/
```

---

### üîπ Load using Keras

```python
from tensorflow.keras.utils import image_dataset_from_directory

train_ds = image_dataset_from_directory(
    "dataset/train",
    image_size=(224, 224),
    batch_size=32
)

test_ds = image_dataset_from_directory(
    "dataset/test",
    image_size=(224, 224),
    batch_size=32
)
```

---

## 4Ô∏è‚É£ Text Dataset Load

### üîπ IMDB Sentiment

```python
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=10000)
```

üëâ Output: integer-encoded text

---

### üîπ Custom text file

```python
from tensorflow.keras.preprocessing.text import Tokenizer

tokenizer = Tokenizer(num_words=5000)
tokenizer.fit_on_texts(texts)
sequences = tokenizer.texts_to_sequences(texts)
```

---

## 5Ô∏è‚É£ TensorFlow Dataset API (`tf.data`)

### üîπ Why use it?

‚úî Faster
‚úî Handles big data
‚úî Pipeline optimization

---

### üîπ From NumPy

```python
dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))
dataset = dataset.shuffle(1000).batch(32)
```

---

### üîπ From CSV

```python
dataset = tf.data.experimental.make_csv_dataset(
    "data.csv",
    batch_size=32,
    label_name="label"
)
```

---

## 6Ô∏è‚É£ Dataset Preprocessing (Common)

### üîπ Normalize images

```python
x_train = x_train / 255.0
x_test  = x_test / 255.0
```

---

### üîπ One-hot encode labels

```python
from tensorflow.keras.utils import to_categorical

y_train = to_categorical(y_train, num_classes)
y_test  = to_categorical(y_test, num_classes)
```

---

## 7Ô∏è‚É£ Train-Test Split (Custom data)

```python
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)
```

---

## 8Ô∏è‚É£ Common Mistakes üö®

‚ùå Dataset normalize ‡¶®‡¶æ ‡¶ï‡¶∞‡¶æ
‚ùå Wrong input shape
‚ùå Label encoding mismatch
‚ùå RGB vs grayscale confusion

---

## 9Ô∏è‚É£ Quick Cheat Sheet üß†

| Data type | Loader                         |
| --------- | ------------------------------ |
| Built-in  | `tf.keras.datasets`            |
| CSV       | `pandas.read_csv`              |
| Images    | `image_dataset_from_directory` |
| Text      | `Tokenizer`                    |
| Big data  | `tf.data.Dataset`              |

---

## üîü End-to-End Example (MNIST)

```python
import tensorflow as tf

(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

x_train = x_train / 255.0
x_test  = x_test / 255.0
```

---

## üîë One-line Summary

> **Dataset loading ‡¶π‡¶≤‡ßã ML pipeline-‡¶è‡¶∞ foundation‚Äî‡¶è‡¶ü‡¶æ ‡¶†‡¶ø‡¶ï ‡¶π‡¶≤‡ßá ‡¶¨‡¶æ‡¶ï‡¶ø ‡¶∏‡¶¨ ‡¶∏‡¶π‡¶ú ‡¶π‡ßü**

---

